{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1bc3f1",
   "metadata": {},
   "source": [
    "Installation - if you're not using Colab, you will need to install `tensorflow` and `tensorflow-datasets` as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ac143",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/am1tyadav/teal pydub -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416065ce",
   "metadata": {},
   "source": [
    "Restart kernel after installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35931b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eab692",
   "metadata": {},
   "source": [
    "Import TensorFlow, TFDS and Teal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from IPython.display import Audio\n",
    "import tensorflow_datasets as tfds\n",
    "import teal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1d6909",
   "metadata": {},
   "source": [
    "Download the Spoken Digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f11f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load(\"spoken_digit\", data_dir=\"./tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66dceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 8000\n",
    "DURATION = 1\n",
    "SAMPLE_LEN = DURATION * SAMPLE_RATE\n",
    "N_FFT = 1024\n",
    "HOP_LEN = 256\n",
    "N_MELS = 28\n",
    "\n",
    "\n",
    "def generate_noise():\n",
    "    return tf.random.uniform(\n",
    "        shape=(SAMPLE_LEN, ), minval=-0.005, maxval=0.005,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "#     f = np.random.randint(400, 800)\n",
    "#     x = np.arange(SAMPLE_LEN)\n",
    "#     return np.random.uniform(0.01, 0.1, size=(1, )) * np.sin(2 * np.pi * f * x / SAMPLE_RATE)\n",
    "\n",
    "\n",
    "def process_example_audio(example):\n",
    "    audio = example[\"audio\"]\n",
    "    audio = tf.cast(audio, dtype=tf.float32) / 32768.\n",
    "\n",
    "    num_samples = tf.shape(audio)[0]\n",
    "    \n",
    "    if num_samples > SAMPLE_LEN:\n",
    "        output = audio[:SAMPLE_LEN]\n",
    "    else:\n",
    "        # Otherwise pad audio \n",
    "        padding = SAMPLE_LEN - num_samples\n",
    "\n",
    "        if padding == 0:\n",
    "            output = audio\n",
    "        else:\n",
    "            output = tf.pad(audio, [[0, padding]])\n",
    "\n",
    "    noisy = output + generate_noise()\n",
    "    return output, noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "TOTAL_EXAMPLES = len(dataset[\"train\"])\n",
    "NUM_TRAIN = int(0.7 * TOTAL_EXAMPLES)\n",
    "NUM_VALID = TOTAL_EXAMPLES - NUM_TRAIN\n",
    "\n",
    "\n",
    "dataset = dataset[\"train\"]\n",
    "dataset = dataset.map(process_example_audio)\n",
    "\n",
    "print(f\"Splitting dataset into {NUM_TRAIN} training examples and {NUM_VALID} validation examples\")\n",
    "\n",
    "train_ds = dataset.take(NUM_TRAIN).batch(BATCH_SIZE)\n",
    "valid_ds = dataset.skip(NUM_TRAIN).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac862954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_processing(clean, noisy):\n",
    "    return {\n",
    "        \"clean\": clean,\n",
    "        \"noisy\": noisy\n",
    "    }\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(batch_processing).cache()\n",
    "valid_ds = valid_ds.map(batch_processing).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c3a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = next(iter(train_ds.take(1)))\n",
    "\n",
    "clean = examples[\"clean\"]\n",
    "noisy = examples[\"noisy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ebea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(clean[0], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(noisy[0], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605bcae",
   "metadata": {},
   "source": [
    "We will create a model using `tf.keras` Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mel_model():\n",
    "    _input = layers.Input(shape=(SAMPLE_LEN, ))\n",
    "    \n",
    "    _stft = teal.AudioToSTFT(n_fft=N_FFT, hop_length=HOP_LEN)(_input)\n",
    "    _spec, _phase = teal.STFTToSpecAndPhase()(_stft)\n",
    "    _mel_spec = teal.SpectrogramToMelSpec(sample_rate=SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS)(_spec)\n",
    "    _log_mel_spec = teal.PowerToDb()(_mel_spec)\n",
    "    _log_mel_spec = teal.NormalizeSpectrum()(_log_mel_spec)\n",
    "    \n",
    "    _model = models.Model(\n",
    "        _input, [_log_mel_spec, _phase],\n",
    "        name=\"feature_model\"\n",
    "    )\n",
    "    return _model\n",
    "\n",
    "\n",
    "def create_autoencoder(feature_model):\n",
    "    _input = layers.Input(shape=(SAMPLE_LEN, ))\n",
    "    _log_mel_spec, _phase = feature_model(_input)\n",
    "    \n",
    "    # Spec Encoder\n",
    "    _x = layers.Flatten()(_log_mel_spec)\n",
    "    _x = layers.Dense(128, activation=\"tanh\")(_x)\n",
    "    _x = layers.LayerNormalization()(_x)\n",
    "    _x = layers.Dense(8, activation=\"tanh\")(_x)\n",
    "    _x = layers.LayerNormalization()(_x)\n",
    "    \n",
    "    # Spec Decoder\n",
    "    _x = layers.Dense(128, activation=\"tanh\")(_x)\n",
    "    _x = layers.LayerNormalization()(_x)\n",
    "    _x = layers.Dense(28 * 28, activation=\"tanh\")(_x)\n",
    "    _x = layers.Reshape((28, 28))(_x)\n",
    "    _pred_log_mel_spec = teal.NormalizeSpectrum()(_x)\n",
    "    \n",
    "    _model = models.Model(\n",
    "        _input, [_pred_log_mel_spec, _phase],\n",
    "        name=\"autoencoder\"\n",
    "    )\n",
    "    return _model\n",
    "\n",
    "\n",
    "_feature_model = log_mel_model()\n",
    "_base_model = create_autoencoder(_feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed532564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss layer\n",
    "class LossLayer(layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        _spec_clean, _spec_noisy = inputs\n",
    "        \n",
    "        cos_spec = tf.keras.losses.CosineSimilarity()(_spec_clean, _spec_noisy)\n",
    "        mse_spec = tf.keras.losses.MeanSquaredError()(_spec_clean, _spec_noisy)\n",
    "        \n",
    "        spec_loss = 1. + cos_spec + mse_spec\n",
    "        return spec_loss\n",
    "\n",
    "\n",
    "# Create siamese network\n",
    "_input_clean = layers.Input(shape=(SAMPLE_LEN, ), name=\"clean\")\n",
    "_input_noisy = layers.Input(shape=(SAMPLE_LEN, ), name=\"noisy\")\n",
    "\n",
    "_spec_clean, _ = _feature_model(_input_clean)\n",
    "_spec_noisy, _ = _base_model(_input_noisy)\n",
    "\n",
    "_loss = LossLayer()([_spec_clean, _spec_noisy])\n",
    "\n",
    "_siamese_net = models.Model(\n",
    "    [_input_clean, _input_noisy],\n",
    "    [_spec_clean, _spec_noisy],\n",
    "    name=\"siamese_net\"\n",
    ")\n",
    "\n",
    "_siamese_net.add_loss(_loss)\n",
    "_siamese_net.compile(optimizer=\"adam\")\n",
    "\n",
    "_siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58557f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = _siamese_net.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.8),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_log_mel_to_audio(log_mel_spec, phase):\n",
    "    _mel_spec = teal.DbToPower()(log_mel_spec)\n",
    "    _spec = teal.MelSpecToSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, n_mels=N_MELS)(_mel_spec)\n",
    "    _stft = teal.SpecAndPhaseToSTFT()([_spec, phase])\n",
    "    _audio = teal.STFTToAudio(n_fft=N_FFT, hop_length=HOP_LEN)(_stft)\n",
    "    return teal.NormalizeAudio()(_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_examples = iter(valid_ds.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024731bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = next(valid_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec2f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = examples[\"clean\"]\n",
    "noisy = examples[\"noisy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pred_log_mel, _phase = _base_model(noisy)\n",
    "_pred_audio = invert_log_mel_to_audio(_pred_log_mel, _phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa0f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3\n",
    "\n",
    "Audio(clean[index], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(noisy[index], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29478b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(_pred_log_mel[index]);\n",
    "\n",
    "Audio(_pred_audio[index], rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f945a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1cdfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
