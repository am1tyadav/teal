{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f910b0b",
   "metadata": {},
   "source": [
    "# Audio Classifier\n",
    "\n",
    "Train a CNN based classifier with __TensorFlow__ and __Teal__ on GTZAN Music Speech dataset\n",
    "\n",
    "Install Teal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6278c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/am1tyadav/teal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0057dcef",
   "metadata": {},
   "source": [
    "Restart kernel for installation to take effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d82cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a2204",
   "metadata": {},
   "source": [
    "Import TensorFlow and Teal after the kernel restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbee401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import teal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e487c",
   "metadata": {},
   "source": [
    "## Download GTZAN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load(name=\"gtzan_music_speech\", data_dir=\"./tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(example):\n",
    "    audio = example[\"audio\"]\n",
    "    label = example[\"label\"]\n",
    "    audio = tf.cast(audio, dtype=tf.float32) / 32768.\n",
    "    label = tf.cast(label, dtype=tf.float32)\n",
    "    \n",
    "    audio_splits = tf.split(audio, num_or_size_splits=10, axis=0)\n",
    "    label = tf.repeat(label, repeats=10)\n",
    "    return audio_splits, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37800722",
   "metadata": {},
   "source": [
    "There are 64 files per class and we divide each file in 10 examples making 640 examples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "train_dataset = train_dataset.map(process_example)\n",
    "train_dataset = train_dataset.unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb91cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EXAMPLES = len(train_dataset)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=TOTAL_EXAMPLES).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf18d13",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032dcac",
   "metadata": {},
   "source": [
    "### Feature Model - Log Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LEN = 66150\n",
    "SAMPLE_RATE = 22050\n",
    "N_FFT = 1024\n",
    "HOP_LEN = 512\n",
    "N_MELS = 128\n",
    "\n",
    "\n",
    "feature_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SAMPLE_LEN, )),\n",
    "    teal.NormalizeAudio(),\n",
    "    teal.AudioToMelSpectrogram(SAMPLE_RATE, N_FFT, HOP_LEN, N_MELS),\n",
    "    teal.PowerToDb(),\n",
    "    teal.NormalizeSpectrum()\n",
    "], name=\"feature_model\")\n",
    "\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b569a1",
   "metadata": {},
   "source": [
    "### Augmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SAMPLE_LEN, )),\n",
    "    teal.InversePolarity(0.5),\n",
    "    teal.RandomGain(0.2),\n",
    "    teal.RandomNoise(0.4),\n",
    "    teal.PitchShift(0.5, 200),\n",
    "    teal.RandomGain(0.2)\n",
    "], name=\"augmentation_model\")\n",
    "\n",
    "aug_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54956bb",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(128, 128)),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1)),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(128, 3, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"cnn\")\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3c939",
   "metadata": {},
   "source": [
    "### Composite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d34ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = tf.keras.layers.Input(shape=(SAMPLE_LEN, ))\n",
    "_data = aug_model(_input)\n",
    "_feature = feature_model(_data)\n",
    "_output = cnn(_feature)\n",
    "\n",
    "model = tf.keras.models.Model(_input, _output, name=\"composite_model\")\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55ba23",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794806bb",
   "metadata": {},
   "source": [
    "## Saving Model for Production\n",
    "\n",
    "You probably don't want the augmentation model/ layers in your deployed model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4af411",
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = model.input\n",
    "\n",
    "_feature = model.layers[2](_input)\n",
    "_output = model.layers[3](_feature)\n",
    "\n",
    "model = tf.keras.models.Model(_input, _output, name=\"prod_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815e8b8d",
   "metadata": {},
   "source": [
    "## Get Some Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a7f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, labels = next(iter(train_dataset))\n",
    "\n",
    "preds = model.predict(examples)\n",
    "\n",
    "preds > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels > 0.5).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49afd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
